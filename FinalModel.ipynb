{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8ade7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64950a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED_BASE = 235\n",
    "\n",
    "N_SPLITS = 5\n",
    "VAL_DAYS = 30\n",
    "STEP_DAYS = 30\n",
    "GAP_HOURS = 0\n",
    "\n",
    "N_TRIALS = 50\n",
    "N_SEEDS_ENSEMBLE = 3\n",
    "\n",
    "FINAL_NUM_BOOST_ROUNDS = 20000\n",
    "EARLY_STOP = 400\n",
    "\n",
    "EPS = 1e-6\n",
    "\n",
    "def rmse(y_true, y_pred) -> float:\n",
    "    return float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "\n",
    "def make_fixed_horizon_folds(df, n_splits=5, val_days=30, step_days=30, gap_hours=0, time_col=\"delivery_start\"):\n",
    "    t = pd.to_datetime(df[time_col])\n",
    "    tmax = t.max()\n",
    "\n",
    "    folds = []\n",
    "    for k in range(n_splits):\n",
    "        val_end = tmax - pd.Timedelta(days=step_days * k)\n",
    "        val_start = val_end - pd.Timedelta(days=val_days)\n",
    "        train_end = val_start - pd.Timedelta(hours=gap_hours)\n",
    "\n",
    "        tr_idx = df.index[t <= train_end]\n",
    "        va_idx = df.index[(t > train_end) & (t <= val_end)]\n",
    "\n",
    "        if len(tr_idx) < 1000 or len(va_idx) < 200:\n",
    "            continue\n",
    "\n",
    "        folds.append((tr_idx.to_numpy(), va_idx.to_numpy()))\n",
    "\n",
    "    folds = folds[::-1]\n",
    "    return folds\n",
    "\n",
    "def recency_weights(df, half_life_days=90, time_col=\"delivery_start\"):\n",
    "    t = pd.to_datetime(df[time_col])\n",
    "    age_days = (t.max() - t).dt.total_seconds() / 86400.0\n",
    "    w = np.exp(-age_days / float(half_life_days))\n",
    "    return w.to_numpy(dtype=np.float32)\n",
    "\n",
    "def preprocess_and_engineer_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df[\"delivery_start\"] = pd.to_datetime(df[\"delivery_start\"])\n",
    "    df[\"delivery_end\"] = pd.to_datetime(df[\"delivery_end\"])\n",
    "\n",
    "    df[\"market\"] = df[\"market\"].astype(\"category\")\n",
    "    df = df.sort_values([\"market\", \"delivery_start\"]).reset_index(drop=True)\n",
    "\n",
    "    ds = df[\"delivery_start\"]\n",
    "    df[\"hour\"] = ds.dt.hour.astype(np.int8)\n",
    "    df[\"dayofweek\"] = ds.dt.dayofweek.astype(np.int8)\n",
    "    df[\"month\"] = ds.dt.month.astype(np.int8)\n",
    "    df[\"dayofyear\"] = ds.dt.dayofyear.astype(np.int16)\n",
    "    df[\"weekofyear\"] = ds.dt.isocalendar().week.astype(np.int16)\n",
    "    df[\"dayofmonth\"] = ds.dt.day.astype(np.int8)\n",
    "\n",
    "    df[\"is_weekend\"] = (df[\"dayofweek\"] >= 5).astype(np.int8)\n",
    "    df[\"is_peak_hour\"] = ((df[\"hour\"] >= 8) & (df[\"hour\"] <= 20)).astype(np.int8)\n",
    "\n",
    "    df[\"hour_sin\"] = np.sin(2 * np.pi * df[\"hour\"] / 24.0)\n",
    "    df[\"hour_cos\"] = np.cos(2 * np.pi * df[\"hour\"] / 24.0)\n",
    "    df[\"dow_sin\"] = np.sin(2 * np.pi * df[\"dayofweek\"] / 7.0)\n",
    "    df[\"dow_cos\"] = np.cos(2 * np.pi * df[\"dayofweek\"] / 7.0)\n",
    "    df[\"doy_sin\"] = np.sin(2 * np.pi * df[\"dayofyear\"] / 365.0)\n",
    "    df[\"doy_cos\"] = np.cos(2 * np.pi * df[\"dayofyear\"] / 365.0)\n",
    "    df[\"month_sin\"] = np.sin(2 * np.pi * df[\"month\"] / 12.0)\n",
    "    df[\"month_cos\"] = np.cos(2 * np.pi * df[\"month\"] / 12.0)\n",
    "\n",
    "    wd = df[\"wind_direction_80m\"].astype(np.float32)\n",
    "    wd_rad = np.deg2rad(wd)\n",
    "    df[\"wind_dir80_sin\"] = np.sin(wd_rad)\n",
    "    df[\"wind_dir80_cos\"] = np.cos(wd_rad)\n",
    "\n",
    "    df[\"net_load_forecast\"] = df[\"load_forecast\"] - (df[\"solar_forecast\"] + df[\"wind_forecast\"])\n",
    "    df[\"temp_deviation\"] = df[\"apparent_temperature_2m\"] - df[\"air_temperature_2m\"]\n",
    "    df[\"wind_shear_approx\"] = df[\"wind_speed_80m\"] - df[\"wind_speed_10m\"]\n",
    "\n",
    "    df[\"net_load_x_peak\"] = df[\"net_load_forecast\"] * df[\"is_peak_hour\"]\n",
    "    df[\"cooling_degree_proxy\"] = np.maximum(df[\"air_temperature_2m\"] - 18.0, 0)\n",
    "    df[\"heating_degree_proxy\"] = np.maximum(18.0 - df[\"air_temperature_2m\"], 0)\n",
    "\n",
    "    df[\"wind_kinetic_10m\"] = df[\"wind_speed_10m\"] ** 3\n",
    "    df[\"wind_kinetic_80m\"] = df[\"wind_speed_80m\"] ** 3\n",
    "    df[\"solar_temp_penalty\"] = df[\"solar_forecast\"] * np.maximum(df[\"air_temperature_2m\"] - 25.0, 0)\n",
    "\n",
    "    df[\"t_hours\"] = ((df[\"delivery_start\"] - df[\"delivery_start\"].min()).dt.total_seconds() / 3600.0).astype(np.float32)\n",
    "\n",
    "    g_nl = df.groupby(\"market\")[\"net_load_forecast\"]\n",
    "    df[\"net_load_ramp\"] = g_nl.diff()\n",
    "    df[\"solar_ramp\"] = df.groupby(\"market\")[\"solar_forecast\"].diff()\n",
    "    df[\"wind_ramp\"] = df.groupby(\"market\")[\"wind_forecast\"].diff()\n",
    "\n",
    "    base_cols = [\n",
    "        \"load_forecast\", \"solar_forecast\", \"wind_forecast\", \"net_load_forecast\",\n",
    "        \"air_temperature_2m\", \"cloud_cover_total\", \"surface_pressure\"\n",
    "    ]\n",
    "    lags = [1, 2, 3, 6, 12, 24, 48, 168]\n",
    "    rolls = [6, 24, 48, 168]\n",
    "\n",
    "    for col in base_cols:\n",
    "        gc = df.groupby(\"market\")[col]\n",
    "\n",
    "        for L in lags:\n",
    "            df[f\"{col}_lag{L}\"] = gc.shift(L)\n",
    "\n",
    "        df[f\"{col}_delta24\"] = df[col] - df[f\"{col}_lag24\"]\n",
    "        df[f\"{col}_delta168\"] = df[col] - df[f\"{col}_lag168\"]\n",
    "\n",
    "        for W in rolls:\n",
    "            df[f\"{col}_roll{W}_mean\"] = gc.transform(lambda x: x.rolling(W, min_periods=1).mean())\n",
    "            df[f\"{col}_roll{W}_std\"] = gc.transform(lambda x: x.rolling(W, min_periods=2).std(ddof=0))\n",
    "\n",
    "        df[f\"{col}_ewm24\"] = gc.transform(lambda x: x.ewm(span=24, adjust=False).mean())\n",
    "        df[f\"{col}_ewm168\"] = gc.transform(lambda x: x.ewm(span=168, adjust=False).mean())\n",
    "\n",
    "    return df\n",
    "\n",
    "print(\"Loading data...\")\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test_for_participants.csv\")\n",
    "\n",
    "train[\"is_test\"] = 0\n",
    "test[\"is_test\"] = 1\n",
    "test[\"target\"] = np.nan\n",
    "\n",
    "df = pd.concat([train, test], ignore_index=True)\n",
    "\n",
    "print(\"Feature engineering...\")\n",
    "df = preprocess_and_engineer_features(df)\n",
    "\n",
    "raw_inputs = [\n",
    "    \"global_horizontal_irradiance\", \"diffuse_horizontal_irradiance\", \"direct_normal_irradiance\",\n",
    "    \"cloud_cover_total\", \"cloud_cover_low\", \"cloud_cover_mid\", \"cloud_cover_high\",\n",
    "    \"precipitation_amount\", \"visibility\", \"air_temperature_2m\", \"apparent_temperature_2m\",\n",
    "    \"dew_point_temperature_2m\", \"wet_bulb_temperature_2m\", \"surface_pressure\", \"freezing_level_height\",\n",
    "    \"relative_humidity_2m\", \"convective_available_potential_energy\", \"lifted_index\", \"convective_inhibition\",\n",
    "    \"wind_speed_80m\", \"wind_direction_80m\", \"wind_gust_speed_10m\", \"wind_speed_10m\",\n",
    "    \"solar_forecast\", \"wind_forecast\", \"load_forecast\"\n",
    "]\n",
    "raw_inputs = [c for c in raw_inputs if c in df.columns]\n",
    "df[raw_inputs] = df.groupby(\"market\")[raw_inputs].ffill()\n",
    "\n",
    "for c in df.columns:\n",
    "    if df[c].dtype == \"float64\":\n",
    "        df[c] = df[c].astype(\"float32\")\n",
    "\n",
    "train_df = df[df[\"is_test\"] == 0].copy()\n",
    "test_df = df[df[\"is_test\"] == 1].copy()\n",
    "\n",
    "train_df = train_df.sort_values(\"delivery_start\").reset_index(drop=True)\n",
    "test_df = test_df.sort_values(\"id\").reset_index(drop=True)\n",
    "\n",
    "drop_cols = [\"id\", \"target\", \"delivery_start\", \"delivery_end\", \"is_test\"]\n",
    "features = [c for c in train_df.columns if c not in drop_cols]\n",
    "\n",
    "X = train_df[features]\n",
    "y = train_df[\"target\"].astype(np.float32)\n",
    "X_test = test_df[features]\n",
    "\n",
    "cat_features = [\"market\"]\n",
    "\n",
    "folds = make_fixed_horizon_folds(\n",
    "    train_df,\n",
    "    n_splits=N_SPLITS,\n",
    "    val_days=VAL_DAYS,\n",
    "    step_days=STEP_DAYS,\n",
    "    gap_hours=GAP_HOURS\n",
    ")\n",
    "assert len(folds) > 0, \"No valid folds constructed â€” reduce VAL_DAYS/STEP_DAYS or check timestamps.\"\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"objective\": \"rmse\",\n",
    "        \"boosting_type\": trial.suggest_categorical(\"boosting_type\", [\"gbdt\"]),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.005, 0.05, log=True),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 31, 255),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 4, 16),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 10, 200),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        \"subsample_freq\": trial.suggest_int(\"subsample_freq\", 1, 10),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-8, 10.0, log=True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-8, 10.0, log=True),\n",
    "        \"min_gain_to_split\": trial.suggest_float(\"min_gain_to_split\", 0.0, 2.0),\n",
    "        \"max_bin\": trial.suggest_int(\"max_bin\", 128, 512),\n",
    "        \"cat_smooth\": trial.suggest_float(\"cat_smooth\", 1.0, 100.0, log=True),\n",
    "        \"cat_l2\": trial.suggest_float(\"cat_l2\", 1e-3, 10.0, log=True),\n",
    "        \"n_estimators\": 20000,\n",
    "        \"random_state\": SEED_BASE,\n",
    "        \"n_jobs\": -1,\n",
    "        \"verbose\": -1,\n",
    "        \"force_col_wise\": True,\n",
    "    }\n",
    "\n",
    "    if params[\"boosting_type\"] == \"dart\":\n",
    "        params[\"drop_rate\"] = trial.suggest_float(\"drop_rate\", 0.05, 0.3)\n",
    "        params[\"skip_drop\"] = trial.suggest_float(\"skip_drop\", 0.2, 0.8)\n",
    "\n",
    "    half_life = trial.suggest_float(\"half_life_days\", 20.0, 180.0)\n",
    "    w_all = recency_weights(train_df, half_life_days=half_life)\n",
    "\n",
    "    scores = []\n",
    "    for tr_idx, va_idx in folds:\n",
    "        Xtr, Xva = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "        ytr, yva = y.iloc[tr_idx], y.iloc[va_idx]\n",
    "        wtr, wva = w_all[tr_idx], w_all[va_idx]\n",
    "\n",
    "        model = lgb.LGBMRegressor(**params)\n",
    "        model.fit(\n",
    "            Xtr, ytr,\n",
    "            sample_weight=wtr,\n",
    "            eval_set=[(Xva, yva)],\n",
    "            eval_metric=\"rmse\",\n",
    "            eval_sample_weight=[wva],\n",
    "            categorical_feature=cat_features,\n",
    "            callbacks=[lgb.early_stopping(EARLY_STOP, verbose=False)],\n",
    "        )\n",
    "        pred = model.predict(Xva, num_iteration=model.best_iteration_)\n",
    "        scores.append(rmse(yva, pred))\n",
    "\n",
    "    return float(np.mean(scores))\n",
    "\n",
    "print(f\"Optuna tuning ({N_TRIALS} trials)...\")\n",
    "study = optuna.create_study(\n",
    "    study_name=\"power_market_lgbm_v1\",\n",
    "    storage=\"sqlite:///optuna_history.db\",\n",
    "    load_if_exists=True,\n",
    "    direction=\"minimize\"\n",
    ")\n",
    "study.optimize(objective, n_trials=N_TRIALS, show_progress_bar=True)\n",
    "\n",
    "print(f\"\\nBest CV RMSE: {study.best_value:.4f}\")\n",
    "best = dict(study.best_params)\n",
    "\n",
    "best_half_life = float(best.pop(\"half_life_days\"))\n",
    "\n",
    "final_params = {\n",
    "    \"objective\": \"rmse\",\n",
    "    \"n_estimators\": FINAL_NUM_BOOST_ROUNDS,\n",
    "    \"random_state\": SEED_BASE,\n",
    "    \"n_jobs\": -1,\n",
    "    \"verbose\": -1,\n",
    "    \"force_col_wise\": True,\n",
    "    **best\n",
    "}\n",
    "\n",
    "print(\"\\nTraining final multi-seed ensemble...\")\n",
    "test_pred = np.zeros(len(X_test), dtype=np.float64)\n",
    "oof = np.zeros(len(X), dtype=np.float64)\n",
    "\n",
    "seeds = [SEED_BASE + i for i in range(N_SEEDS_ENSEMBLE)]\n",
    "w_all = recency_weights(train_df, half_life_days=best_half_life)\n",
    "\n",
    "for s_i, seed in enumerate(seeds, 1):\n",
    "    fold_pred = np.zeros(len(X_test), dtype=np.float64)\n",
    "    fold_scores = []\n",
    "\n",
    "    params_seeded = dict(final_params)\n",
    "    params_seeded[\"random_state\"] = seed\n",
    "\n",
    "    for f, (tr_idx, va_idx) in enumerate(folds, 1):\n",
    "        Xtr, Xva = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "        ytr, yva = y.iloc[tr_idx], y.iloc[va_idx]\n",
    "        wtr, wva = w_all[tr_idx], w_all[va_idx]\n",
    "\n",
    "        model = lgb.LGBMRegressor(**params_seeded)\n",
    "        model.fit(\n",
    "            Xtr, ytr,\n",
    "            sample_weight=wtr,\n",
    "            eval_set=[(Xva, yva)],\n",
    "            eval_metric=\"rmse\",\n",
    "            categorical_feature=cat_features,\n",
    "            callbacks=[lgb.early_stopping(EARLY_STOP, verbose=False)],\n",
    "        )\n",
    "\n",
    "        va_pred = model.predict(Xva, num_iteration=model.best_iteration_)\n",
    "        fold_scores.append(rmse(yva, va_pred))\n",
    "        oof[va_idx] += va_pred / len(seeds)\n",
    "\n",
    "        fold_pred += model.predict(X_test, num_iteration=model.best_iteration_) / len(folds)\n",
    "\n",
    "    print(f\"Seed {seed} | mean fold RMSE: {np.mean(fold_scores):.4f}\")\n",
    "    test_pred += fold_pred / len(seeds)\n",
    "\n",
    "valid_mask = oof != 0.0\n",
    "actual_oof_rmse = rmse(y.iloc[valid_mask], oof[valid_mask])\n",
    "print(f\"\\nOOF RMSE (on validated horizons only): {actual_oof_rmse:.4f}\")\n",
    "\n",
    "predictions = pd.DataFrame({\n",
    "    \"id\": pd.to_numeric(test_df[\"id\"], errors=\"raise\").astype(\"int64\"),\n",
    "    \"target\": np.asarray(test_pred, dtype=np.float32),\n",
    "})\n",
    "\n",
    "assert len(predictions) == len(test_df)\n",
    "assert predictions[\"id\"].notna().all()\n",
    "assert predictions[\"id\"].duplicated().sum() == 0\n",
    "assert predictions[\"target\"].notna().all()\n",
    "assert np.isfinite(predictions[\"target\"]).all()\n",
    "\n",
    "predictions = predictions.sort_values(\"id\").reset_index(drop=True)\n",
    "\n",
    "predictions.to_csv(\"final_submission_lgbm_improved.csv\", index=False)\n",
    "print(\"Saved: final_submission_lgbm_improved.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93336a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = \"train.csv\"\n",
    "TEST_PATH  = \"test_for_participants.csv\"\n",
    "OUT_PATH   = \"submission_new_anton.csv\"\n",
    "\n",
    "VAL_DAYS = 30\n",
    "NETLOAD_Q = 0.90\n",
    "\n",
    "MODE = \"per_market\"\n",
    "OBJECTIVE = \"huber\"\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "def rmse(y_true, y_pred) -> float:\n",
    "    return float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "\n",
    "def add_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    df[\"delivery_start\"] = pd.to_datetime(df[\"delivery_start\"])\n",
    "    df[\"delivery_end\"] = pd.to_datetime(df[\"delivery_end\"])\n",
    "    df[\"market\"] = df[\"market\"].astype(str)\n",
    "\n",
    "    dt = df[\"delivery_start\"]\n",
    "    hour = dt.dt.hour\n",
    "\n",
    "    df[\"dayofweek\"] = dt.dt.dayofweek.astype(\"int8\")\n",
    "    df[\"is_weekend\"] = (df[\"dayofweek\"] >= 5).astype(\"int8\")\n",
    "    df[\"month\"] = dt.dt.month.astype(\"int8\")\n",
    "    df[\"dayofyear\"] = dt.dt.dayofyear.astype(\"int16\")\n",
    "    df[\"weekofyear\"] = dt.dt.isocalendar().week.astype(\"int16\")\n",
    "\n",
    "    df[\"hour_sin\"] = np.sin(2 * np.pi * hour / 24.0)\n",
    "    df[\"hour_cos\"] = np.cos(2 * np.pi * hour / 24.0)\n",
    "\n",
    "    df[\"renewables_forecast\"] = df[\"solar_forecast\"] + df[\"wind_forecast\"]\n",
    "    df[\"net_load_forecast\"] = df[\"load_forecast\"] - df[\"renewables_forecast\"]\n",
    "\n",
    "    df[\"netload_x_hour_sin\"] = df[\"net_load_forecast\"] * df[\"hour_sin\"]\n",
    "    df[\"netload_x_hour_cos\"] = df[\"net_load_forecast\"] * df[\"hour_cos\"]\n",
    "\n",
    "    return df\n",
    "\n",
    "def sort_ffill_by_market(df: pd.DataFrame, cols: list[str]) -> pd.DataFrame:\n",
    "    df = df.sort_values([\"market\", \"delivery_start\"]).copy()\n",
    "    df[cols] = df.groupby(\"market\", sort=False)[cols].ffill()\n",
    "    return df\n",
    "\n",
    "def add_scarcity(df: pd.DataFrame, thr: float) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df[\"scarcity_flag\"] = (df[\"net_load_forecast\"] > thr).astype(\"int8\")\n",
    "    df[\"net_load_scarcity\"] = df[\"net_load_forecast\"] * df[\"scarcity_flag\"]\n",
    "    return df\n",
    "\n",
    "def build_feature_list(train_df: pd.DataFrame, test_df: pd.DataFrame, include_market: bool) -> list[str]:\n",
    "    drop = {\"target\", \"delivery_start\", \"delivery_end\"}\n",
    "    if not include_market:\n",
    "        drop.add(\"market\")\n",
    "\n",
    "    common = [c for c in train_df.columns if c in test_df.columns]\n",
    "    num_cols = []\n",
    "    for c in common:\n",
    "        if c in drop:\n",
    "            continue\n",
    "        if pd.api.types.is_numeric_dtype(train_df[c]):\n",
    "            num_cols.append(c)\n",
    "\n",
    "    engineered = [\n",
    "        \"dayofweek\", \"is_weekend\", \"month\", \"dayofyear\", \"weekofyear\",\n",
    "        \"hour_sin\", \"hour_cos\",\n",
    "        \"renewables_forecast\", \"net_load_forecast\",\n",
    "        \"netload_x_hour_sin\", \"netload_x_hour_cos\",\n",
    "        \"scarcity_flag\", \"net_load_scarcity\",\n",
    "    ]\n",
    "    for c in engineered:\n",
    "        if c in train_df.columns and c not in num_cols and c not in drop:\n",
    "            num_cols.append(c)\n",
    "\n",
    "    return num_cols\n",
    "\n",
    "def make_regressor(objective: str, n_estimators: int = 20000) -> LGBMRegressor:\n",
    "    return LGBMRegressor(\n",
    "        objective=objective,\n",
    "        n_estimators=n_estimators,\n",
    "        learning_rate=0.02,\n",
    "        num_leaves=127,\n",
    "        max_depth=-1,\n",
    "        min_data_in_leaf=100,\n",
    "        feature_fraction=0.9,\n",
    "        bagging_fraction=0.9,\n",
    "        bagging_freq=1,\n",
    "        lambda_l2=3.0,\n",
    "        random_state=SEED,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1,\n",
    "    )\n",
    "\n",
    "def run_per_market(train: pd.DataFrame, test: pd.DataFrame):\n",
    "    markets = sorted(train[\"market\"].unique())\n",
    "    print(\"Markets:\", markets)\n",
    "\n",
    "    preds_test = np.full(len(test), np.nan, dtype=float)\n",
    "    all_true, all_pred = [], []\n",
    "\n",
    "    for m in markets:\n",
    "        tr_m = train[train[\"market\"] == m].copy()\n",
    "        te_m = test[test[\"market\"] == m].copy()\n",
    "        if len(tr_m) < 2000 or len(te_m) == 0:\n",
    "            print(f\"Market {m} | skipped (train {len(tr_m):,}, test {len(te_m):,})\")\n",
    "            continue\n",
    "\n",
    "        cutoff = tr_m[\"delivery_start\"].max() - pd.Timedelta(days=VAL_DAYS)\n",
    "        tr = tr_m[tr_m[\"delivery_start\"] < cutoff].copy()\n",
    "        va = tr_m[tr_m[\"delivery_start\"] >= cutoff].copy()\n",
    "\n",
    "        thr = float(tr[\"net_load_forecast\"].quantile(NETLOAD_Q))\n",
    "        tr = add_scarcity(tr, thr)\n",
    "        va = add_scarcity(va, thr)\n",
    "\n",
    "        feats = build_feature_list(tr, te_m, include_market=False)\n",
    "\n",
    "        tr = sort_ffill_by_market(tr, feats)\n",
    "        va = sort_ffill_by_market(va, feats)\n",
    "\n",
    "        reg = make_regressor(OBJECTIVE)\n",
    "        reg.fit(\n",
    "            tr[feats], tr[\"target\"].values,\n",
    "            eval_set=[(va[feats], va[\"target\"].values)],\n",
    "            eval_metric=\"rmse\",\n",
    "            callbacks=[lgb.early_stopping(300, verbose=False)],\n",
    "        )\n",
    "\n",
    "        pred_va = reg.predict(va[feats])\n",
    "        score = rmse(va[\"target\"].values, pred_va)\n",
    "        best_it = int(getattr(reg, \"best_iteration_\", reg.n_estimators))\n",
    "\n",
    "        print(f\"Market {m} | RMSE {score:8.3f} | val rows {len(va):,} | best_iter {best_it:,} | netload_thr(q{NETLOAD_Q:.2f}) {thr:,.0f}\")\n",
    "\n",
    "        all_true.append(va[\"target\"].values)\n",
    "        all_pred.append(pred_va)\n",
    "\n",
    "        thr_full = float(tr_m[\"net_load_forecast\"].quantile(NETLOAD_Q))\n",
    "        tr_full = add_scarcity(tr_m, thr_full)\n",
    "\n",
    "        te_full = add_scarcity(te_m, thr_full)\n",
    "\n",
    "        feats_full = build_feature_list(tr_full, te_full, include_market=False)\n",
    "        tr_full = sort_ffill_by_market(tr_full, feats_full)\n",
    "        te_full = sort_ffill_by_market(te_full, feats_full)\n",
    "\n",
    "        reg_final = make_regressor(OBJECTIVE, n_estimators=best_it)\n",
    "        reg_final.fit(tr_full[feats_full], tr_full[\"target\"].values)\n",
    "\n",
    "        pred_test_m = reg_final.predict(te_full[feats_full])\n",
    "        preds_test[test[\"market\"] == m] = pred_test_m\n",
    "\n",
    "    if all_pred:\n",
    "        y_true = np.concatenate(all_true)\n",
    "        y_pred = np.concatenate(all_pred)\n",
    "        print(\"\\nOverall validation RMSE:\", f\"{rmse(y_true, y_pred):.4f}\")\n",
    "\n",
    "    return preds_test\n",
    "\n",
    "def run_global(train: pd.DataFrame, test: pd.DataFrame):\n",
    "    train = train.copy()\n",
    "    test = test.copy()\n",
    "\n",
    "    cutoff = train[\"delivery_start\"].max() - pd.Timedelta(days=VAL_DAYS)\n",
    "    tr = train[train[\"delivery_start\"] < cutoff].copy()\n",
    "    va = train[train[\"delivery_start\"] >= cutoff].copy()\n",
    "\n",
    "    thr_by_market = tr.groupby(\"market\")[\"net_load_forecast\"].quantile(NETLOAD_Q).to_dict()\n",
    "\n",
    "    def apply_thr(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df = df.copy()\n",
    "        df[\"thr\"] = df[\"market\"].map(thr_by_market).astype(float)\n",
    "        df[\"scarcity_flag\"] = (df[\"net_load_forecast\"] > df[\"thr\"]).astype(\"int8\")\n",
    "        df[\"net_load_scarcity\"] = df[\"net_load_forecast\"] * df[\"scarcity_flag\"]\n",
    "        df.drop(columns=[\"thr\"], inplace=True)\n",
    "        return df\n",
    "\n",
    "    tr = apply_thr(tr)\n",
    "    va = apply_thr(va)\n",
    "    test2 = apply_thr(test)\n",
    "\n",
    "    tr[\"market\"] = tr[\"market\"].astype(\"category\")\n",
    "    va[\"market\"] = va[\"market\"].astype(\"category\")\n",
    "    test2[\"market\"] = test2[\"market\"].astype(\"category\")\n",
    "\n",
    "    feats = build_feature_list(tr, test2, include_market=True)\n",
    "    feats_ffill = [c for c in feats if c != \"market\"]\n",
    "    tr = sort_ffill_by_market(tr, feats_ffill)\n",
    "    va = sort_ffill_by_market(va, feats_ffill)\n",
    "    test2 = sort_ffill_by_market(test2, feats_ffill)\n",
    "\n",
    "    reg = make_regressor(OBJECTIVE)\n",
    "    reg.fit(\n",
    "        tr[feats], tr[\"target\"].values,\n",
    "        eval_set=[(va[feats], va[\"target\"].values)],\n",
    "        eval_metric=\"rmse\",\n",
    "        categorical_feature=[\"market\"],\n",
    "        callbacks=[lgb.early_stopping(300, verbose=False)],\n",
    "    )\n",
    "\n",
    "    pred_va = reg.predict(va[feats])\n",
    "    print(\"Overall validation RMSE:\", f\"{rmse(va['target'].values, pred_va):.4f}\")\n",
    "\n",
    "    for m in sorted(train[\"market\"].unique()):\n",
    "        mask = va[\"market\"].astype(str) == m\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "        print(f\"Market {m} | RMSE {rmse(va.loc[mask,'target'].values, pred_va[mask]):8.3f} | val rows {mask.sum():,}\")\n",
    "\n",
    "    best_it = int(getattr(reg, \"best_iteration_\", reg.n_estimators))\n",
    "\n",
    "    train_full = train.copy()\n",
    "    thr_full = train_full.groupby(\"market\")[\"net_load_forecast\"].quantile(NETLOAD_Q).to_dict()\n",
    "\n",
    "    def apply_thr_full(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df = df.copy()\n",
    "        df[\"thr\"] = df[\"market\"].map(thr_full).astype(float)\n",
    "        df[\"scarcity_flag\"] = (df[\"net_load_forecast\"] > df[\"thr\"]).astype(\"int8\")\n",
    "        df[\"net_load_scarcity\"] = df[\"net_load_forecast\"] * df[\"scarcity_flag\"]\n",
    "        df.drop(columns=[\"thr\"], inplace=True)\n",
    "        return df\n",
    "\n",
    "    train_full = apply_thr_full(train_full)\n",
    "    test_full = apply_thr_full(test.copy())\n",
    "\n",
    "    train_full[\"market\"] = train_full[\"market\"].astype(\"category\")\n",
    "    test_full[\"market\"] = test_full[\"market\"].astype(\"category\")\n",
    "\n",
    "    feats_full = build_feature_list(train_full, test_full, include_market=True)\n",
    "    feats_ffill_full = [c for c in feats_full if c != \"market\"]\n",
    "    train_full = sort_ffill_by_market(train_full, feats_ffill_full)\n",
    "    test_full = sort_ffill_by_market(test_full, feats_ffill_full)\n",
    "\n",
    "    reg_final = make_regressor(OBJECTIVE, n_estimators=best_it)\n",
    "    reg_final.fit(\n",
    "        train_full[feats_full], train_full[\"target\"].values,\n",
    "        categorical_feature=[\"market\"],\n",
    "    )\n",
    "\n",
    "    return reg_final.predict(test_full[feats_full])\n",
    "\n",
    "def main():\n",
    "    train = pd.read_csv(TRAIN_PATH)\n",
    "    test = pd.read_csv(TEST_PATH)\n",
    "\n",
    "    train = add_features(train)\n",
    "    test = add_features(test)\n",
    "\n",
    "    if MODE == \"per_market\":\n",
    "        preds = run_per_market(train, test)\n",
    "    elif MODE == \"global\":\n",
    "        preds = run_global(train, test)\n",
    "    else:\n",
    "        raise ValueError(\"MODE must be 'per_market' or 'global'\")\n",
    "\n",
    "    if np.isnan(preds).any():\n",
    "        missing = int(np.isnan(preds).sum())\n",
    "        raise RuntimeError(f\"{missing} test predictions are NaN (likely a market mismatch).\")\n",
    "\n",
    "    sub = pd.DataFrame({\"id\": test[\"id\"].values, \"target\": preds})\n",
    "    sub.to_csv(OUT_PATH, index=False)\n",
    "    print(f\"\\nWrote: {OUT_PATH} | rows: {len(sub):,}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291a8a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading submission files and test map...\")\n",
    "\n",
    "sub_market_a = pd.read_csv(\"final_submission_lgbm_improved.csv\")\n",
    "sub_rest     = pd.read_csv(\"submission_new_anton.csv\")\n",
    "test_df      = pd.read_csv(\"test_for_participants.csv\")\n",
    "\n",
    "required_cols = {\"id\", \"market\"}\n",
    "assert required_cols.issubset(test_df.columns), f\"test_df must contain {required_cols}\"\n",
    "assert {\"id\", \"target\"}.issubset(sub_market_a.columns)\n",
    "assert {\"id\", \"target\"}.issubset(sub_rest.columns)\n",
    "\n",
    "test_ids = pd.to_numeric(test_df[\"id\"], errors=\"raise\").astype(\"int64\")\n",
    "test_markets = test_df[\"market\"]\n",
    "\n",
    "subA = sub_market_a.copy()\n",
    "subB = sub_rest.copy()\n",
    "subA[\"id\"] = pd.to_numeric(subA[\"id\"], errors=\"raise\").astype(\"int64\")\n",
    "subB[\"id\"] = pd.to_numeric(subB[\"id\"], errors=\"raise\").astype(\"int64\")\n",
    "\n",
    "subA = subA.set_index(\"id\")[[\"target\"]]\n",
    "subB = subB.set_index(\"id\")[[\"target\"]]\n",
    "\n",
    "assert test_ids.is_unique, \"Duplicate IDs in test file\"\n",
    "\n",
    "A_missing = set(test_ids) - set(subA.index)\n",
    "B_missing = set(test_ids) - set(subB.index)\n",
    "assert len(A_missing) == 0, f\"sub_market_a missing {len(A_missing)} test IDs\"\n",
    "assert len(B_missing) == 0, f\"sub_rest missing {len(B_missing)} test IDs\"\n",
    "\n",
    "TARGET_MARKET_VALUE = \"Market A\"\n",
    "\n",
    "mask = (test_markets == TARGET_MARKET_VALUE).to_numpy()\n",
    "\n",
    "targets_A = subA.loc[test_ids, \"target\"].to_numpy()\n",
    "targets_B = subB.loc[test_ids, \"target\"].to_numpy()\n",
    "\n",
    "stitched_sub = pd.DataFrame({\n",
    "    \"id\": test_ids.to_numpy(),\n",
    "    \"target\": np.where(mask, targets_A, targets_B).astype(np.float32)\n",
    "})\n",
    "\n",
    "assert list(stitched_sub.columns) == [\"id\", \"target\"]\n",
    "assert len(stitched_sub) == len(test_df)\n",
    "assert stitched_sub[\"id\"].is_unique\n",
    "assert stitched_sub[\"target\"].notna().all()\n",
    "assert np.isfinite(stitched_sub[\"target\"]).all()\n",
    "\n",
    "stitched_sub = stitched_sub.sort_values(\"id\").reset_index(drop=True)\n",
    "\n",
    "stitched_sub.to_csv(\"aey_trading_submission.csv\", index=False)\n",
    "print(\"Success! Saved to 'final_stitched_submission.csv'.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
