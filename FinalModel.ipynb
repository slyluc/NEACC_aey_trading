{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8ade7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64950a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED_BASE = 235\n",
    "\n",
    "N_SPLITS = 5\n",
    "VAL_DAYS = 30\n",
    "STEP_DAYS = 30\n",
    "GAP_HOURS = 0\n",
    "\n",
    "N_TRIALS = 50\n",
    "N_SEEDS_ENSEMBLE = 3\n",
    "\n",
    "FINAL_NUM_BOOST_ROUNDS = 20000\n",
    "EARLY_STOP = 400\n",
    "\n",
    "EPS = 1e-6\n",
    "\n",
    "def rmse(y_true, y_pred) -> float:\n",
    "    return float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "\n",
    "def make_fixed_horizon_folds(df, n_splits=5, val_days=30, step_days=30, gap_hours=0, time_col=\"delivery_start\"):\n",
    "    t = pd.to_datetime(df[time_col])\n",
    "    tmax = t.max()\n",
    "\n",
    "    folds = []\n",
    "    for k in range(n_splits):\n",
    "        val_end = tmax - pd.Timedelta(days=step_days * k)\n",
    "        val_start = val_end - pd.Timedelta(days=val_days)\n",
    "        train_end = val_start - pd.Timedelta(hours=gap_hours)\n",
    "\n",
    "        tr_idx = df.index[t <= train_end]\n",
    "        va_idx = df.index[(t > train_end) & (t <= val_end)]\n",
    "\n",
    "        if len(tr_idx) < 1000 or len(va_idx) < 200:\n",
    "            continue\n",
    "\n",
    "        folds.append((tr_idx.to_numpy(), va_idx.to_numpy()))\n",
    "\n",
    "    folds = folds[::-1]\n",
    "    return folds\n",
    "\n",
    "def recency_weights(df, half_life_days=90, time_col=\"delivery_start\"):\n",
    "    t = pd.to_datetime(df[time_col])\n",
    "    age_days = (t.max() - t).dt.total_seconds() / 86400.0\n",
    "    w = np.exp(-age_days / float(half_life_days))\n",
    "    return w.to_numpy(dtype=np.float32)\n",
    "\n",
    "def preprocess_and_engineer_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df[\"delivery_start\"] = pd.to_datetime(df[\"delivery_start\"])\n",
    "    df[\"delivery_end\"] = pd.to_datetime(df[\"delivery_end\"])\n",
    "\n",
    "    df[\"market\"] = df[\"market\"].astype(\"category\")\n",
    "    df = df.sort_values([\"market\", \"delivery_start\"]).reset_index(drop=True)\n",
    "\n",
    "    ds = df[\"delivery_start\"]\n",
    "    df[\"hour\"] = ds.dt.hour.astype(np.int8)\n",
    "    df[\"dayofweek\"] = ds.dt.dayofweek.astype(np.int8)\n",
    "    df[\"month\"] = ds.dt.month.astype(np.int8)\n",
    "    df[\"dayofyear\"] = ds.dt.dayofyear.astype(np.int16)\n",
    "    df[\"weekofyear\"] = ds.dt.isocalendar().week.astype(np.int16)\n",
    "    df[\"dayofmonth\"] = ds.dt.day.astype(np.int8)\n",
    "\n",
    "    df[\"is_weekend\"] = (df[\"dayofweek\"] >= 5).astype(np.int8)\n",
    "    df[\"is_peak_hour\"] = ((df[\"hour\"] >= 8) & (df[\"hour\"] <= 20)).astype(np.int8)\n",
    "\n",
    "    df[\"hour_sin\"] = np.sin(2 * np.pi * df[\"hour\"] / 24.0)\n",
    "    df[\"hour_cos\"] = np.cos(2 * np.pi * df[\"hour\"] / 24.0)\n",
    "    df[\"dow_sin\"] = np.sin(2 * np.pi * df[\"dayofweek\"] / 7.0)\n",
    "    df[\"dow_cos\"] = np.cos(2 * np.pi * df[\"dayofweek\"] / 7.0)\n",
    "    df[\"doy_sin\"] = np.sin(2 * np.pi * df[\"dayofyear\"] / 365.0)\n",
    "    df[\"doy_cos\"] = np.cos(2 * np.pi * df[\"dayofyear\"] / 365.0)\n",
    "    df[\"month_sin\"] = np.sin(2 * np.pi * df[\"month\"] / 12.0)\n",
    "    df[\"month_cos\"] = np.cos(2 * np.pi * df[\"month\"] / 12.0)\n",
    "\n",
    "    wd = df[\"wind_direction_80m\"].astype(np.float32)\n",
    "    wd_rad = np.deg2rad(wd)\n",
    "    df[\"wind_dir80_sin\"] = np.sin(wd_rad)\n",
    "    df[\"wind_dir80_cos\"] = np.cos(wd_rad)\n",
    "\n",
    "    df[\"net_load_forecast\"] = df[\"load_forecast\"] - (df[\"solar_forecast\"] + df[\"wind_forecast\"])\n",
    "    df[\"temp_deviation\"] = df[\"apparent_temperature_2m\"] - df[\"air_temperature_2m\"]\n",
    "    df[\"wind_shear_approx\"] = df[\"wind_speed_80m\"] - df[\"wind_speed_10m\"]\n",
    "\n",
    "    df[\"net_load_x_peak\"] = df[\"net_load_forecast\"] * df[\"is_peak_hour\"]\n",
    "    df[\"cooling_degree_proxy\"] = np.maximum(df[\"air_temperature_2m\"] - 18.0, 0)\n",
    "    df[\"heating_degree_proxy\"] = np.maximum(18.0 - df[\"air_temperature_2m\"], 0)\n",
    "\n",
    "    df[\"wind_kinetic_10m\"] = df[\"wind_speed_10m\"] ** 3\n",
    "    df[\"wind_kinetic_80m\"] = df[\"wind_speed_80m\"] ** 3\n",
    "    df[\"solar_temp_penalty\"] = df[\"solar_forecast\"] * np.maximum(df[\"air_temperature_2m\"] - 25.0, 0)\n",
    "\n",
    "    df[\"t_hours\"] = ((df[\"delivery_start\"] - df[\"delivery_start\"].min()).dt.total_seconds() / 3600.0).astype(np.float32)\n",
    "\n",
    "    g_nl = df.groupby(\"market\")[\"net_load_forecast\"]\n",
    "    df[\"net_load_ramp\"] = g_nl.diff()\n",
    "    df[\"solar_ramp\"] = df.groupby(\"market\")[\"solar_forecast\"].diff()\n",
    "    df[\"wind_ramp\"] = df.groupby(\"market\")[\"wind_forecast\"].diff()\n",
    "\n",
    "    base_cols = [\n",
    "        \"load_forecast\", \"solar_forecast\", \"wind_forecast\", \"net_load_forecast\",\n",
    "        \"air_temperature_2m\", \"cloud_cover_total\", \"surface_pressure\"\n",
    "    ]\n",
    "    lags = [1, 2, 3, 6, 12, 24, 48, 168]\n",
    "    rolls = [6, 24, 48, 168]\n",
    "\n",
    "    for col in base_cols:\n",
    "        gc = df.groupby(\"market\")[col]\n",
    "\n",
    "        for L in lags:\n",
    "            df[f\"{col}_lag{L}\"] = gc.shift(L)\n",
    "\n",
    "        df[f\"{col}_delta24\"] = df[col] - df[f\"{col}_lag24\"]\n",
    "        df[f\"{col}_delta168\"] = df[col] - df[f\"{col}_lag168\"]\n",
    "\n",
    "        for W in rolls:\n",
    "            df[f\"{col}_roll{W}_mean\"] = gc.transform(lambda x: x.rolling(W, min_periods=1).mean())\n",
    "            df[f\"{col}_roll{W}_std\"] = gc.transform(lambda x: x.rolling(W, min_periods=2).std(ddof=0))\n",
    "\n",
    "        df[f\"{col}_ewm24\"] = gc.transform(lambda x: x.ewm(span=24, adjust=False).mean())\n",
    "        df[f\"{col}_ewm168\"] = gc.transform(lambda x: x.ewm(span=168, adjust=False).mean())\n",
    "\n",
    "    return df\n",
    "\n",
    "print(\"Loading data...\")\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test_for_participants.csv\")\n",
    "\n",
    "train[\"is_test\"] = 0\n",
    "test[\"is_test\"] = 1\n",
    "test[\"target\"] = np.nan\n",
    "\n",
    "df = pd.concat([train, test], ignore_index=True)\n",
    "\n",
    "print(\"Feature engineering...\")\n",
    "df = preprocess_and_engineer_features(df)\n",
    "\n",
    "raw_inputs = [\n",
    "    \"global_horizontal_irradiance\", \"diffuse_horizontal_irradiance\", \"direct_normal_irradiance\",\n",
    "    \"cloud_cover_total\", \"cloud_cover_low\", \"cloud_cover_mid\", \"cloud_cover_high\",\n",
    "    \"precipitation_amount\", \"visibility\", \"air_temperature_2m\", \"apparent_temperature_2m\",\n",
    "    \"dew_point_temperature_2m\", \"wet_bulb_temperature_2m\", \"surface_pressure\", \"freezing_level_height\",\n",
    "    \"relative_humidity_2m\", \"convective_available_potential_energy\", \"lifted_index\", \"convective_inhibition\",\n",
    "    \"wind_speed_80m\", \"wind_direction_80m\", \"wind_gust_speed_10m\", \"wind_speed_10m\",\n",
    "    \"solar_forecast\", \"wind_forecast\", \"load_forecast\"\n",
    "]\n",
    "raw_inputs = [c for c in raw_inputs if c in df.columns]\n",
    "df[raw_inputs] = df.groupby(\"market\")[raw_inputs].ffill()\n",
    "\n",
    "for c in df.columns:\n",
    "    if df[c].dtype == \"float64\":\n",
    "        df[c] = df[c].astype(\"float32\")\n",
    "\n",
    "train_df = df[df[\"is_test\"] == 0].copy()\n",
    "test_df = df[df[\"is_test\"] == 1].copy()\n",
    "\n",
    "train_df = train_df.sort_values(\"delivery_start\").reset_index(drop=True)\n",
    "test_df = test_df.sort_values(\"id\").reset_index(drop=True)\n",
    "\n",
    "drop_cols = [\"id\", \"target\", \"delivery_start\", \"delivery_end\", \"is_test\"]\n",
    "features = [c for c in train_df.columns if c not in drop_cols]\n",
    "\n",
    "X = train_df[features]\n",
    "y = train_df[\"target\"].astype(np.float32)\n",
    "X_test = test_df[features]\n",
    "\n",
    "cat_features = [\"market\"]\n",
    "\n",
    "folds = make_fixed_horizon_folds(\n",
    "    train_df,\n",
    "    n_splits=N_SPLITS,\n",
    "    val_days=VAL_DAYS,\n",
    "    step_days=STEP_DAYS,\n",
    "    gap_hours=GAP_HOURS\n",
    ")\n",
    "assert len(folds) > 0, \"No valid folds constructed â€” reduce VAL_DAYS/STEP_DAYS or check timestamps.\"\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"objective\": \"rmse\",\n",
    "        \"boosting_type\": trial.suggest_categorical(\"boosting_type\", [\"gbdt\"]),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.005, 0.05, log=True),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 31, 255),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 4, 16),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 10, 200),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        \"subsample_freq\": trial.suggest_int(\"subsample_freq\", 1, 10),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-8, 10.0, log=True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-8, 10.0, log=True),\n",
    "        \"min_gain_to_split\": trial.suggest_float(\"min_gain_to_split\", 0.0, 2.0),\n",
    "        \"max_bin\": trial.suggest_int(\"max_bin\", 128, 512),\n",
    "        \"cat_smooth\": trial.suggest_float(\"cat_smooth\", 1.0, 100.0, log=True),\n",
    "        \"cat_l2\": trial.suggest_float(\"cat_l2\", 1e-3, 10.0, log=True),\n",
    "        \"n_estimators\": 20000,\n",
    "        \"random_state\": SEED_BASE,\n",
    "        \"n_jobs\": -1,\n",
    "        \"verbose\": -1,\n",
    "        \"force_col_wise\": True,\n",
    "    }\n",
    "\n",
    "    if params[\"boosting_type\"] == \"dart\":\n",
    "        params[\"drop_rate\"] = trial.suggest_float(\"drop_rate\", 0.05, 0.3)\n",
    "        params[\"skip_drop\"] = trial.suggest_float(\"skip_drop\", 0.2, 0.8)\n",
    "\n",
    "    half_life = trial.suggest_float(\"half_life_days\", 20.0, 180.0)\n",
    "    w_all = recency_weights(train_df, half_life_days=half_life)\n",
    "\n",
    "    scores = []\n",
    "    for tr_idx, va_idx in folds:\n",
    "        Xtr, Xva = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "        ytr, yva = y.iloc[tr_idx], y.iloc[va_idx]\n",
    "        wtr, wva = w_all[tr_idx], w_all[va_idx]\n",
    "\n",
    "        model = lgb.LGBMRegressor(**params)\n",
    "        model.fit(\n",
    "            Xtr, ytr,\n",
    "            sample_weight=wtr,\n",
    "            eval_set=[(Xva, yva)],\n",
    "            eval_metric=\"rmse\",\n",
    "            eval_sample_weight=[wva],\n",
    "            categorical_feature=cat_features,\n",
    "            callbacks=[lgb.early_stopping(EARLY_STOP, verbose=False)],\n",
    "        )\n",
    "        pred = model.predict(Xva, num_iteration=model.best_iteration_)\n",
    "        scores.append(rmse(yva, pred))\n",
    "\n",
    "    return float(np.mean(scores))\n",
    "\n",
    "print(f\"Optuna tuning ({N_TRIALS} trials)...\")\n",
    "study = optuna.create_study(\n",
    "    study_name=\"power_market_lgbm_v1\",\n",
    "    storage=\"sqlite:///optuna_history.db\",\n",
    "    load_if_exists=True,\n",
    "    direction=\"minimize\"\n",
    ")\n",
    "study.optimize(objective, n_trials=N_TRIALS, show_progress_bar=True)\n",
    "\n",
    "print(f\"\\nBest CV RMSE: {study.best_value:.4f}\")\n",
    "best = dict(study.best_params)\n",
    "\n",
    "best_half_life = float(best.pop(\"half_life_days\"))\n",
    "\n",
    "final_params = {\n",
    "    \"objective\": \"rmse\",\n",
    "    \"n_estimators\": FINAL_NUM_BOOST_ROUNDS,\n",
    "    \"random_state\": SEED_BASE,\n",
    "    \"n_jobs\": -1,\n",
    "    \"verbose\": -1,\n",
    "    \"force_col_wise\": True,\n",
    "    **best\n",
    "}\n",
    "\n",
    "print(\"\\nTraining final multi-seed ensemble...\")\n",
    "test_pred = np.zeros(len(X_test), dtype=np.float64)\n",
    "oof = np.zeros(len(X), dtype=np.float64)\n",
    "\n",
    "seeds = [SEED_BASE + i for i in range(N_SEEDS_ENSEMBLE)]\n",
    "w_all = recency_weights(train_df, half_life_days=best_half_life)\n",
    "\n",
    "for s_i, seed in enumerate(seeds, 1):\n",
    "    fold_pred = np.zeros(len(X_test), dtype=np.float64)\n",
    "    fold_scores = []\n",
    "\n",
    "    params_seeded = dict(final_params)\n",
    "    params_seeded[\"random_state\"] = seed\n",
    "\n",
    "    for f, (tr_idx, va_idx) in enumerate(folds, 1):\n",
    "        Xtr, Xva = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "        ytr, yva = y.iloc[tr_idx], y.iloc[va_idx]\n",
    "        wtr, wva = w_all[tr_idx], w_all[va_idx]\n",
    "\n",
    "        model = lgb.LGBMRegressor(**params_seeded)\n",
    "        model.fit(\n",
    "            Xtr, ytr,\n",
    "            sample_weight=wtr,\n",
    "            eval_set=[(Xva, yva)],\n",
    "            eval_metric=\"rmse\",\n",
    "            categorical_feature=cat_features,\n",
    "            callbacks=[lgb.early_stopping(EARLY_STOP, verbose=False)],\n",
    "        )\n",
    "\n",
    "        va_pred = model.predict(Xva, num_iteration=model.best_iteration_)\n",
    "        fold_scores.append(rmse(yva, va_pred))\n",
    "        oof[va_idx] += va_pred / len(seeds)\n",
    "\n",
    "        fold_pred += model.predict(X_test, num_iteration=model.best_iteration_) / len(folds)\n",
    "\n",
    "    print(f\"Seed {seed} | mean fold RMSE: {np.mean(fold_scores):.4f}\")\n",
    "    test_pred += fold_pred / len(seeds)\n",
    "\n",
    "valid_mask = oof != 0.0\n",
    "actual_oof_rmse = rmse(y.iloc[valid_mask], oof[valid_mask])\n",
    "print(f\"\\nOOF RMSE (on validated horizons only): {actual_oof_rmse:.4f}\")\n",
    "\n",
    "predictions = pd.DataFrame({\n",
    "    \"id\": pd.to_numeric(test_df[\"id\"], errors=\"raise\").astype(\"int64\"),\n",
    "    \"target\": np.asarray(test_pred, dtype=np.float32),\n",
    "})\n",
    "\n",
    "assert len(predictions) == len(test_df)\n",
    "assert predictions[\"id\"].notna().all()\n",
    "assert predictions[\"id\"].duplicated().sum() == 0\n",
    "assert predictions[\"target\"].notna().all()\n",
    "assert np.isfinite(predictions[\"target\"]).all()\n",
    "\n",
    "predictions = predictions.sort_values(\"id\").reset_index(drop=True)\n",
    "\n",
    "predictions.to_csv(\"aey__trading_submission.csv\", index=False)\n",
    "print(\"Saved: aey__trading_submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
